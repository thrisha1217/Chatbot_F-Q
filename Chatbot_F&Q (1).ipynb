{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMjDYtK6iDW6",
        "outputId": "523972c3-e919-4bd6-dcf7-7db5b18dff61"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lIYO6WtzVyeQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "941d7a80-9372-4ffe-b8bf-5ee739615224"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.4/20.4 MB\u001b[0m \u001b[31m137.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.5/323.5 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m142.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m101.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "google-adk 1.16.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\n",
            "google-adk 1.16.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain-community chromadb pypdf sentence-transformers openai -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_community.chat_models import ChatOpenAI\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.schema import Document\n",
        "\n",
        "# --- Step 3: Set up the API Key and Environment ---\n",
        "# IMPORTANT: Before running, you must add your OpenRouter API key to Colab's secrets.\n",
        "# 1. Click the 'Key' icon on the left sidebar.\n",
        "# 2. Add a new secret named \"OPENROUTER_API_KEY\" and paste your key as the value.\n",
        "try:\n",
        "    os.environ[\"OPENROUTER_API_KEY\"] = userdata.get(\"OPENROUTER_API_KEY\")\n",
        "except Exception as e:\n",
        "    print(\"ERROR: Could not find the OPENROUTER_API_KEY secret.\")\n",
        "    print(\"Please add your OpenRouter API key to Colab's secrets (on the left sidebar) and try again.\")\n",
        "    # Stop execution if the key is not found\n",
        "    raise SystemExit(e)\n",
        "\n",
        "\n",
        "# --- Step 4: Load and Process the PDF Document ---\n",
        "# Updated the pdf_path to the new file you provided.\n",
        "pdf_path = \"/content/drive/MyDrive/RIL-IAR-2025.pdf\"\n",
        "if not os.path.exists(pdf_path):\n",
        "    print(f\"ERROR: The file '{pdf_path}' was not found.\")\n",
        "    print(\"Please upload the 'RIL-IAR-2025.pdf' file to your Colab session.\")\n",
        "else:\n",
        "    print(\"Loading and processing the PDF... this may take a moment.\")\n",
        "    # Load the PDF\n",
        "    loader = PyPDFLoader(pdf_path)\n",
        "    pages = loader.load_and_split()\n",
        "\n",
        "    # Split the document into smaller chunks for processing\n",
        "    pdf_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=1000,\n",
        "        chunk_overlap=200,\n",
        "        length_function=len\n",
        "    )\n",
        "    docs = pdf_splitter.split_documents(pages)\n",
        "    documents = [Document(page_content=doc.page_content) for doc in docs]\n",
        "\n",
        "    # --- Step 5: Create Text Embeddings and Vector Store ---\n",
        "    # This converts the text chunks into numerical vectors for similarity searching.\n",
        "    print(\"Creating text embeddings and vector store...\")\n",
        "    embeddings = HuggingFaceEmbeddings(\n",
        "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "        model_kwargs={'device': 'cpu'}\n",
        "    )\n",
        "    vector_db = Chroma.from_documents(\n",
        "        documents,\n",
        "        embedding=embeddings\n",
        "    )\n",
        "\n",
        "    # --- Step 6: Set Up the Conversational AI Model ---\n",
        "    # This configures the chatbot's \"brain\" and memory.\n",
        "    print(\"Setting up the conversational AI...\")\n",
        "    # Set up conversational memory to remember the chat history\n",
        "    memory = ConversationBufferMemory(\n",
        "        memory_key=\"chat_history\",\n",
        "        return_messages=True\n",
        "    )\n",
        "\n",
        "    # Initialize the Language Model (LLM) through OpenRouter\n",
        "    llm = ChatOpenAI(\n",
        "        model=\"openai/gpt-3.5-turbo\",\n",
        "        temperature=0.2,\n",
        "        openai_api_base=\"https://openrouter.ai/api/v1\",\n",
        "        max_tokens=500,\n",
        "        openai_api_key=os.environ[\"OPENROUTER_API_KEY\"]\n",
        "    )\n",
        "\n",
        "    # Combine the retriever (from the vector store) and the LLM into a conversational chain\n",
        "    qa_chain = ConversationalRetrievalChain.from_llm(\n",
        "        llm=llm,\n",
        "        retriever=vector_db.as_retriever(),\n",
        "        memory=memory\n",
        "    )\n",
        "\n",
        "    print(\"\\n✅ Setup complete! The chatbot is ready.\")\n",
        "    print(\"You can now ask questions about the Reliance Industries 2024-25 Annual Report.\")\n",
        "    print(\"Type 'Exit' to end the chat.\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # --- Step 7: Start the Real-time Interaction Loop ---\n",
        "    while True:\n",
        "        try:\n",
        "            question = input(\"User: \")\n",
        "            if question.lower().strip() == \"exit\":\n",
        "                print(\"Bot: Thank you for chatting. Goodbye!\")\n",
        "                break\n",
        "            if not question.strip():\n",
        "                continue\n",
        "\n",
        "            # Get the answer from the QA chain\n",
        "            answer = qa_chain({\"question\": question})\n",
        "            print(\"Bot:\", answer[\"answer\"])\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}\")\n",
        "            break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVPl-61BeUNk",
        "outputId": "2acc46a8-b73c-4539-dc0a-8c2598bbefd2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and processing the PDF... this may take a moment.\n",
            "Creating text embeddings and vector store...\n",
            "Setting up the conversational AI...\n",
            "\n",
            "✅ Setup complete! The chatbot is ready.\n",
            "You can now ask questions about the Reliance Industries 2024-25 Annual Report.\n",
            "Type 'Exit' to end the chat.\n",
            "--------------------------------------------------\n",
            "User: what is reliance company is all about?\n",
            "Bot: Reliance Industries Limited is India's largest private sector enterprise and a Fortune Global 500 leader. It operates across various sectors such as energy, retail, telecom, media, and green technologies, impacting millions of lives every day. Reliance is known for its contribution to India's growth momentum and its belief that 'Growth is Life'.\n",
            "User: is reliance a good company?\n",
            "Bot: I don't have enough information to provide an opinion on whether Reliance is a good company or not.\n",
            "User: exit\n",
            "Bot: Thank you for chatting. Goodbye!\n",
            "Loading and processing the PDF... this may take a moment.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KJMCWAdUedr_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}